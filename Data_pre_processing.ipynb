{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data pre-processing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKivV53d2FgoNL58Umrd0s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eslamahmed235/Arabic-dialect-classification-ML-DL/blob/main/Data_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LFXLhG3jWs6",
        "outputId": "b966f59d-eed2-43a5-a227-61136949ae2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-14 17:59:19--  https://docs.google.com/uc?export=download&id=1-7vpa0W7lOtiOXCT_XxzH-63ed5Zo7jk\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.0.46, 2607:f8b0:4004:800::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.0.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i3qpl6el2vafi5gjj4ki7jvd12lvu0v2/1647280725000/15315052740638448697/*/1-7vpa0W7lOtiOXCT_XxzH-63ed5Zo7jk?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-03-14 17:59:20--  https://doc-08-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i3qpl6el2vafi5gjj4ki7jvd12lvu0v2/1647280725000/15315052740638448697/*/1-7vpa0W7lOtiOXCT_XxzH-63ed5Zo7jk?e=download\n",
            "Resolving doc-08-1g-docs.googleusercontent.com (doc-08-1g-docs.googleusercontent.com)... 142.250.81.193, 2607:f8b0:4004:82f::2001\n",
            "Connecting to doc-08-1g-docs.googleusercontent.com (doc-08-1g-docs.googleusercontent.com)|142.250.81.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10339942 (9.9M) [text/csv]\n",
            "Saving to: â€˜dialict.csvâ€™\n",
            "\n",
            "dialict.csv         100%[===================>]   9.86M  55.3MB/s    in 0.2s    \n",
            "\n",
            "2022-03-14 17:59:21 (55.3 MB/s) - â€˜dialict.csvâ€™ saved [10339942/10339942]\n",
            "\n",
            "--2022-03-14 17:59:21--  https://docs.google.com/uc?export=download&id=1-8CiXjf4bmuDS5Q7xVZe3s4iQsua2vER\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.73.206, 2607:f8b0:4004:800::200e\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.73.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hkgt3gnf97046nljqcho5fuui7i7o442/1647280725000/15315052740638448697/*/1-8CiXjf4bmuDS5Q7xVZe3s4iQsua2vER?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-03-14 17:59:23--  https://doc-14-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hkgt3gnf97046nljqcho5fuui7i7o442/1647280725000/15315052740638448697/*/1-8CiXjf4bmuDS5Q7xVZe3s4iQsua2vER?e=download\n",
            "Resolving doc-14-1g-docs.googleusercontent.com (doc-14-1g-docs.googleusercontent.com)... 142.250.81.193, 2607:f8b0:4004:82f::2001\n",
            "Connecting to doc-14-1g-docs.googleusercontent.com (doc-14-1g-docs.googleusercontent.com)|142.250.81.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80136817 (76M) [text/csv]\n",
            "Saving to: â€˜output.csvâ€™\n",
            "\n",
            "output.csv          100%[===================>]  76.42M   128MB/s    in 0.6s    \n",
            "\n",
            "2022-03-14 17:59:24 (128 MB/s) - â€˜output.csvâ€™ saved [80136817/80136817]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-7vpa0W7lOtiOXCT_XxzH-63ed5Zo7jk' -O dialict.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-8CiXjf4bmuDS5Q7xVZe3s4iQsua2vER' -O output.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HioIOdXlBSJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18bf8d2-c183-43d5-8292-419440de6f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json as js\n",
        "from time import sleep\n",
        "\n",
        "from imblearn.pipeline       import Pipeline \n",
        "from sklearn.model_selection import cross_validate\n",
        "from imblearn.over_sampling  import RandomOverSampler\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "# !pip install gensim spacy nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "!pip install pyarabic\n",
        "import pyarabic\n",
        "import pyarabic.araby as araby\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from __future__ import unicode_literals\n",
        "import regex as re\n",
        "\n",
        "from numpy.ma.core import size\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import linear_model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import ComplementNB, GaussianNB , BernoulliNB \n",
        "\n",
        "import pyarabic.araby as araby\n",
        "from pyarabic.araby import normalize_ligature\n",
        "from pyarabic.araby import normalize_hamza\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rb5Ix5uQI7HI"
      },
      "outputs": [],
      "source": [
        "text_data = pd.read_csv(\"/content/output.csv\",lineterminator='\\n')\n",
        "label_data = pd.read_csv(\"/content/dialict.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uM2SFPvtpk34",
        "outputId": "04919833-9005-4749-dcf8-9d787787390d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_id                                              tweet  \\\n",
              "0  1175358310087892992   @Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .   \n",
              "1  1175416117793349632  @7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...   \n",
              "2  1175450108898565888                    @KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ   \n",
              "3  1175471073770573824         @HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’   \n",
              "4  1175496913145217024                 @hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº   \n",
              "\n",
              "  dialect  \n",
              "0      IQ  \n",
              "1      IQ  \n",
              "2      IQ  \n",
              "3      IQ  \n",
              "4      IQ  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5c222ba-6dd6-4862-9439-b062a314ba37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>dialect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1175358310087892992</td>\n",
              "      <td>@Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1175416117793349632</td>\n",
              "      <td>@7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1175450108898565888</td>\n",
              "      <td>@KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1175471073770573824</td>\n",
              "      <td>@HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1175496913145217024</td>\n",
              "      <td>@hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5c222ba-6dd6-4862-9439-b062a314ba37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5c222ba-6dd6-4862-9439-b062a314ba37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5c222ba-6dd6-4862-9439-b062a314ba37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Drop unimportant column\n",
        "text_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "# Merge fetched Data and label by tweet ID\n",
        "Data = pd.merge(text_data, label_data, how='inner', left_on = 'tweet_id', right_on = 'id')\n",
        "Data.drop('id', axis=1, inplace=True)\n",
        "\n",
        "Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j9kvRlzYqMdN"
      },
      "outputs": [],
      "source": [
        "# function to clean hashtag and mention from text\n",
        "def clean_hashtag_and_mention (text):\n",
        "  \n",
        "  text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
        "  text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
        "  return text\n",
        "\n",
        "def clean_tweet(text):\n",
        "    text = re.sub('#\\d+K\\d+', ' ', text)  # years like 2K19\n",
        "    text = re.sub('http\\S+\\s*', ' ', text)  # remove URLs\n",
        "    text = re.sub('RT|cc', ' ', text)  # remove RT and cc\n",
        "    text = re.sub('@[^\\s]+',' ',text)\n",
        "    text = clean_hashtag_and_mention(text)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tvalZoVO0MRF"
      },
      "outputs": [],
      "source": [
        "# fuction to remove emojis by regex \n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                                   u\"\\U00002702-\\U000027B0\"\n",
        "                                   u\"\\U000024C2-\\U0001F251\"\n",
        "                                   \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    return text\n",
        "\n",
        "# Data['clean_tweet'] = Data['clean_tweet'].apply(lambda x:remove_emoji(x))\n",
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RVijYboKxg8E"
      },
      "outputs": [],
      "source": [
        "# call and save most stopwords in arabic\n",
        "stops = set(stopwords.words(\"arabic\"))\n",
        "stop_word_comp = {\"ØŒ\",\"Ø¢Ø¶\",\"Ø¢Ù…ÙŠÙ†Ù\",\"Ø¢Ù‡\",\"Ø¢Ù‡Ø§Ù‹\",\"Ø¢ÙŠ\",\"Ø£\",\"Ø£Ø¨\",\"Ø£Ø¬Ù„\",\"Ø£Ø¬Ù…Ø¹\",\"Ø£Ø®\",\"Ø£Ø®Ø°\",\"Ø£ØµØ¨Ø­\",\"Ø£Ø¶Ø­Ù‰\",\"Ø£Ù‚Ø¨Ù„\",\"Ø£Ù‚Ù„\",\"Ø£ÙƒØ«Ø±\",\"Ø£Ù„Ø§\",\"Ø£Ù…\",\"Ø£Ù…Ø§\",\"Ø£Ù…Ø§Ù…Ùƒ\",\"Ø£Ù…Ø§Ù…ÙƒÙ\",\"Ø£Ù…Ø³Ù‰\",\"Ø£Ù…Ù‘Ø§\",\"Ø£Ù†\",\"Ø£Ù†Ø§\",\"Ø£Ù†Øª\",\"Ø£Ù†ØªÙ…\",\"Ø£Ù†ØªÙ…Ø§\",\"Ø£Ù†ØªÙ†\",\"Ø£Ù†ØªÙ\",\"Ø£Ù†Ø´Ø£\",\"Ø£Ù†Ù‘Ù‰\",\"Ø£Ùˆ\",\"Ø£ÙˆØ´Ùƒ\",\"Ø£ÙˆÙ„Ø¦Ùƒ\",\"Ø£ÙˆÙ„Ø¦ÙƒÙ…\",\"Ø£ÙˆÙ„Ø§Ø¡\",\"Ø£ÙˆÙ„Ø§Ù„Ùƒ\",\"Ø£ÙˆÙ‘Ù‡Ù’\",\"Ø£ÙŠ\",\"Ø£ÙŠØ§\",\"Ø£ÙŠÙ†\",\"Ø£ÙŠÙ†Ù…Ø§\",\"Ø£ÙŠÙ‘\",\"Ø£ÙÙ†Ù‘Ù\",\"Ø£ÙÙÙŠÙ‘Ù\",\"Ø£ÙÙÙ‘Ù\",\"Ø¥Ø°\",\"Ø¥Ø°Ø§\",\"Ø¥Ø°Ø§Ù‹\",\"Ø¥Ø°Ù…Ø§\",\"Ø¥Ø°Ù†\",\"Ø¥Ù„Ù‰\",\"Ø¥Ù„ÙŠÙƒÙ…\",\"Ø¥Ù„ÙŠÙƒÙ…Ø§\",\"Ø¥Ù„ÙŠÙƒÙ†Ù‘\",\"Ø¥Ù„ÙŠÙƒÙ\",\"Ø¥Ù„ÙÙŠÙ’ÙƒÙ\",\"Ø¥Ù„Ù‘Ø§\",\"Ø¥Ù…Ù‘Ø§\",\"Ø¥Ù†\",\"Ø¥Ù†Ù‘Ù…Ø§\",\"Ø¥ÙŠ\",\"Ø¥ÙŠØ§Ùƒ\",\"Ø¥ÙŠØ§ÙƒÙ…\",\"Ø¥ÙŠØ§ÙƒÙ…Ø§\",\"Ø¥ÙŠØ§ÙƒÙ†\",\"Ø¥ÙŠØ§Ù†Ø§\",\"Ø¥ÙŠØ§Ù‡\",\"Ø¥ÙŠØ§Ù‡Ø§\",\"Ø¥ÙŠØ§Ù‡Ù…\",\"Ø¥ÙŠØ§Ù‡Ù…Ø§\",\"Ø¥ÙŠØ§Ù‡Ù†\",\"Ø¥ÙŠØ§ÙŠ\",\"Ø¥ÙŠÙ‡Ù\",\"Ø¥ÙÙ†Ù‘Ù\",\"Ø§\",\"Ø§Ø¨ØªØ¯Ø£\",\"Ø§Ø«Ø±\",\"Ø§Ø¬Ù„\",\"Ø§Ø­Ø¯\",\"Ø§Ø®Ø±Ù‰\",\"Ø§Ø®Ù„ÙˆÙ„Ù‚\",\"Ø§Ø°Ø§\",\"Ø§Ø±Ø¨Ø¹Ø©\",\"Ø§Ø±ØªØ¯Ù‘\",\"Ø§Ø³ØªØ­Ø§Ù„\",\"Ø§Ø·Ø§Ø±\",\"Ø§Ø¹Ø§Ø¯Ø©\",\"Ø§Ø¹Ù„Ù†Øª\",\"Ø§Ù\",\"Ø§ÙƒØ«Ø±\",\"Ø§ÙƒØ¯\",\"Ø§Ù„Ø£Ù„Ø§Ø¡\",\"Ø§Ù„Ø£Ù„Ù‰\",\"Ø§Ù„Ø§\",\"Ø§Ù„Ø§Ø®ÙŠØ±Ø©\",\"Ø§Ù„Ø§Ù†\",\"Ø§Ù„Ø§ÙˆÙ„\",\"Ø§Ù„Ø§ÙˆÙ„Ù‰\",\"Ø§Ù„ØªÙ‰\",\"Ø§Ù„ØªÙŠ\",\"Ø§Ù„Ø«Ø§Ù†ÙŠ\",\"Ø§Ù„Ø«Ø§Ù†ÙŠØ©\",\"Ø§Ù„Ø°Ø§ØªÙŠ\",\"Ø§Ù„Ø°Ù‰\",\"Ø§Ù„Ø°ÙŠ\",\"Ø§Ù„Ø°ÙŠÙ†\",\"Ø§Ù„Ø³Ø§Ø¨Ù‚\",\"Ø§Ù„Ù\",\"Ø§Ù„Ù„Ø§Ø¦ÙŠ\",\"Ø§Ù„Ù„Ø§ØªÙŠ\",\"Ø§Ù„Ù„ØªØ§Ù†\",\"Ø§Ù„Ù„ØªÙŠØ§\",\"Ø§Ù„Ù„ØªÙŠÙ†\",\"Ø§Ù„Ù„Ø°Ø§Ù†\",\"Ø§Ù„Ù„Ø°ÙŠÙ†\",\"Ø§Ù„Ù„ÙˆØ§ØªÙŠ\",\"Ø§Ù„Ù…Ø§Ø¶ÙŠ\",\"Ø§Ù„Ù…Ù‚Ø¨Ù„\",\"Ø§Ù„ÙˆÙ‚Øª\",\"Ø§Ù„Ù‰\",\"Ø§Ù„ÙŠÙˆÙ…\",\"Ø§Ù…Ø§\",\"Ø§Ù…Ø§Ù…\",\"Ø§Ù…Ø³\",\"Ø§Ù†\",\"Ø§Ù†Ø¨Ø±Ù‰\",\"Ø§Ù†Ù‚Ù„Ø¨\",\"Ø§Ù†Ù‡\",\"Ø§Ù†Ù‡Ø§\",\"Ø§Ùˆ\",\"Ø§ÙˆÙ„\",\"Ø§ÙŠ\",\"Ø§ÙŠØ§Ø±\",\"Ø§ÙŠØ§Ù…\",\"Ø§ÙŠØ¶Ø§\",\"Ø¨\",\"Ø¨Ø§Øª\",\"Ø¨Ø§Ø³Ù…\",\"Ø¨Ø§Ù†\",\"Ø¨Ø®Ù\",\"Ø¨Ø±Ø³\",\"Ø¨Ø³Ø¨Ø¨\",\"Ø¨Ø³Ù‘\",\"Ø¨Ø´ÙƒÙ„\",\"Ø¨Ø¶Ø¹\",\"Ø¨Ø·Ø¢Ù†\",\"Ø¨Ø¹Ø¯\",\"Ø¨Ø¹Ø¶\",\"Ø¨Ùƒ\",\"Ø¨ÙƒÙ…\",\"Ø¨ÙƒÙ…Ø§\",\"Ø¨ÙƒÙ†\",\"Ø¨Ù„\",\"Ø¨Ù„Ù‰\",\"Ø¨Ù…Ø§\",\"Ø¨Ù…Ø§Ø°Ø§\",\"Ø¨Ù…Ù†\",\"Ø¨Ù†\",\"Ø¨Ù†Ø§\",\"Ø¨Ù‡\",\"Ø¨Ù‡Ø§\",\"Ø¨ÙŠ\",\"Ø¨ÙŠØ¯\",\"Ø¨ÙŠÙ†\",\"Ø¨ÙØ³Ù’\",\"Ø¨ÙÙ„Ù’Ù‡Ù\",\"Ø¨ÙØ¦Ù’Ø³Ù\",\"ØªØ§Ù†Ù\",\"ØªØ§Ù†ÙÙƒ\",\"ØªØ¨Ø¯Ù‘Ù„\",\"ØªØ¬Ø§Ù‡\",\"ØªØ­ÙˆÙ‘Ù„\",\"ØªÙ„Ù‚Ø§Ø¡\",\"ØªÙ„Ùƒ\",\"ØªÙ„ÙƒÙ…\",\"ØªÙ„ÙƒÙ…Ø§\",\"ØªÙ…\",\"ØªÙŠÙ†Ùƒ\",\"ØªÙÙŠÙ’Ù†Ù\",\"ØªÙÙ‡\",\"ØªÙÙŠ\",\"Ø«Ù„Ø§Ø«Ø©\",\"Ø«Ù…\",\"Ø«Ù…Ù‘\",\"Ø«Ù…Ù‘Ø©\",\"Ø«ÙÙ…Ù‘Ù\",\"Ø¬Ø¹Ù„\",\"Ø¬Ù„Ù„\",\"Ø¬Ù…ÙŠØ¹\",\"Ø¬ÙŠØ±\",\"Ø­Ø§Ø±\",\"Ø­Ø§Ø´Ø§\",\"Ø­Ø§Ù„ÙŠØ§\",\"Ø­Ø§ÙŠ\",\"Ø­ØªÙ‰\",\"Ø­Ø±Ù‰\",\"Ø­Ø³Ø¨\",\"Ø­Ù…\",\"Ø­ÙˆØ§Ù„Ù‰\",\"Ø­ÙˆÙ„\",\"Ø­ÙŠØ«\",\"Ø­ÙŠØ«Ù…Ø§\",\"Ø­ÙŠÙ†\",\"Ø­ÙŠÙ‘Ù\",\"Ø­ÙØ¨Ù‘ÙØ°ÙØ§\",\"Ø­ÙØªÙ‘ÙÙ‰\",\"Ø­ÙØ°Ø§Ø±Ù\",\"Ø®Ù„Ø§\",\"Ø®Ù„Ø§Ù„\",\"Ø¯ÙˆÙ†\",\"Ø¯ÙˆÙ†Ùƒ\",\"Ø°Ø§\",\"Ø°Ø§Øª\",\"Ø°Ø§Ùƒ\",\"Ø°Ø§Ù†Ùƒ\",\"Ø°Ø§Ù†Ù\",\"Ø°Ù„Ùƒ\",\"Ø°Ù„ÙƒÙ…\",\"Ø°Ù„ÙƒÙ…Ø§\",\"Ø°Ù„ÙƒÙ†\",\"Ø°Ùˆ\",\"Ø°ÙˆØ§\",\"Ø°ÙˆØ§ØªØ§\",\"Ø°ÙˆØ§ØªÙŠ\",\"Ø°ÙŠØª\",\"Ø°ÙŠÙ†Ùƒ\",\"Ø°ÙÙŠÙ’Ù†Ù\",\"Ø°ÙÙ‡\",\"Ø°ÙÙŠ\",\"Ø±Ø§Ø­\",\"Ø±Ø¬Ø¹\",\"Ø±ÙˆÙŠØ¯Ùƒ\",\"Ø±ÙŠØ«\",\"Ø±ÙØ¨Ù‘Ù\",\"Ø²ÙŠØ§Ø±Ø©\",\"Ø³Ø¨Ø­Ø§Ù†\",\"Ø³Ø±Ø¹Ø§Ù†\",\"Ø³Ù†Ø©\",\"Ø³Ù†ÙˆØ§Øª\",\"Ø³ÙˆÙ\",\"Ø³ÙˆÙ‰\",\"Ø³ÙØ§Ø¡Ù\",\"Ø³ÙØ§Ø¡ÙÙ…ÙØ§\",\"Ø´Ø¨Ù‡\",\"Ø´Ø®ØµØ§\",\"Ø´Ø±Ø¹\",\"Ø´ÙØªÙ‘ÙØ§Ù†Ù\",\"ØµØ§Ø±\",\"ØµØ¨Ø§Ø­\",\"ØµÙØ±\",\"ØµÙ‡Ù\",\"ØµÙ‡Ù’\",\"Ø¶Ø¯\",\"Ø¶Ù…Ù†\",\"Ø·Ø§Ù‚\",\"Ø·Ø§Ù„Ù…Ø§\",\"Ø·ÙÙ‚\",\"Ø·ÙÙ‚\",\"Ø¸Ù„Ù‘\",\"Ø¹Ø§Ø¯\",\"Ø¹Ø§Ù…\",\"Ø¹Ø§Ù…Ø§\",\"Ø¹Ø§Ù…Ø©\",\"Ø¹Ø¯Ø§\",\"Ø¹Ø¯Ø©\",\"Ø¹Ø¯Ø¯\",\"Ø¹Ø¯Ù…\",\"Ø¹Ø³Ù‰\",\"Ø¹Ø´Ø±\",\"Ø¹Ø´Ø±Ø©\",\"Ø¹Ù„Ù‚\",\"Ø¹Ù„Ù‰\",\"Ø¹Ù„ÙŠÙƒ\",\"Ø¹Ù„ÙŠÙ‡\",\"Ø¹Ù„ÙŠÙ‡Ø§\",\"Ø¹Ù„Ù‘Ù‹\",\"Ø¹Ù†\",\"Ø¹Ù†Ø¯\",\"Ø¹Ù†Ø¯Ù…Ø§\",\"Ø¹ÙˆØ¶\",\"Ø¹ÙŠÙ†\",\"Ø¹ÙØ¯ÙØ³Ù’\",\"Ø¹ÙÙ…Ù‘ÙØ§\",\"ØºØ¯Ø§\",\"ØºÙŠØ±\",\"Ù€\",\"Ù\",\"ÙØ§Ù†\",\"ÙÙ„Ø§Ù†\",\"ÙÙˆ\",\"ÙÙ‰\",\"ÙÙŠ\",\"ÙÙŠÙ…\",\"ÙÙŠÙ…Ø§\",\"ÙÙŠÙ‡\",\"ÙÙŠÙ‡Ø§\",\"Ù‚Ø§Ù„\",\"Ù‚Ø§Ù…\",\"Ù‚Ø¨Ù„\",\"Ù‚Ø¯\",\"Ù‚Ø·Ù‘\",\"Ù‚Ù„Ù…Ø§\",\"Ù‚ÙˆØ©\",\"ÙƒØ£Ù†Ù‘Ù…Ø§\",\"ÙƒØ£ÙŠÙ†\",\"ÙƒØ£ÙŠÙ‘\",\"ÙƒØ£ÙŠÙ‘Ù†\",\"ÙƒØ§Ø¯\",\"ÙƒØ§Ù†\",\"ÙƒØ§Ù†Øª\",\"ÙƒØ°Ø§\",\"ÙƒØ°Ù„Ùƒ\",\"ÙƒØ±Ø¨\",\"ÙƒÙ„\",\"ÙƒÙ„Ø§\",\"ÙƒÙ„Ø§Ù‡Ù…Ø§\",\"ÙƒÙ„ØªØ§\",\"ÙƒÙ„Ù…\",\"ÙƒÙ„ÙŠÙƒÙ…Ø§\",\"ÙƒÙ„ÙŠÙ‡Ù…Ø§\",\"ÙƒÙ„Ù‘Ù…Ø§\",\"ÙƒÙ„Ù‘ÙØ§\",\"ÙƒÙ…\",\"ÙƒÙ…Ø§\",\"ÙƒÙŠ\",\"ÙƒÙŠØª\",\"ÙƒÙŠÙ\",\"ÙƒÙŠÙÙ…Ø§\",\"ÙƒÙØ£ÙÙ†Ù‘Ù\",\"ÙƒÙØ®\",\"Ù„Ø¦Ù†\",\"Ù„Ø§\",\"Ù„Ø§Øª\",\"Ù„Ø§Ø³ÙŠÙ…Ø§\",\"Ù„Ø¯Ù†\",\"Ù„Ø¯Ù‰\",\"Ù„Ø¹Ù…Ø±\",\"Ù„Ù‚Ø§Ø¡\",\"Ù„Ùƒ\",\"Ù„ÙƒÙ…\",\"Ù„ÙƒÙ…Ø§\",\"Ù„ÙƒÙ†\",\"Ù„ÙƒÙ†Ù‘ÙÙ…Ø§\",\"Ù„ÙƒÙŠ\",\"Ù„ÙƒÙŠÙ„Ø§\",\"Ù„Ù„Ø§Ù…Ù…\",\"Ù„Ù…\",\"Ù„Ù…Ø§\",\"Ù„Ù…Ù‘Ø§\",\"Ù„Ù†\",\"Ù„Ù†Ø§\",\"Ù„Ù‡\",\"Ù„Ù‡Ø§\",\"Ù„Ùˆ\",\"Ù„ÙˆÙƒØ§Ù„Ø©\",\"Ù„ÙˆÙ„Ø§\",\"Ù„ÙˆÙ…Ø§\",\"Ù„ÙŠ\",\"Ù„ÙØ³Ù’ØªÙ\",\"Ù„ÙØ³Ù’ØªÙ\",\"Ù„ÙØ³Ù’ØªÙÙ…\",\"Ù„ÙØ³Ù’ØªÙÙ…ÙØ§\",\"Ù„ÙØ³Ù’ØªÙÙ†Ù‘Ù\",\"Ù„ÙØ³Ù’ØªÙ\",\"Ù„ÙØ³Ù’Ù†Ù\",\"Ù„ÙØ¹ÙÙ„Ù‘Ù\",\"Ù„ÙÙƒÙÙ†Ù‘Ù\",\"Ù„ÙÙŠÙ’ØªÙ\",\"Ù„ÙÙŠÙ’Ø³Ù\",\"Ù„ÙÙŠÙ’Ø³ÙØ§\",\"Ù„ÙÙŠÙ’Ø³ÙØªÙØ§\",\"Ù„ÙÙŠÙ’Ø³ÙØªÙ’\",\"Ù„ÙÙŠÙ’Ø³ÙÙˆØ§\",\"Ù„ÙÙØ³Ù’Ù†ÙØ§\",\"Ù…Ø§\",\"Ù…Ø§Ø§Ù†ÙÙƒ\",\"Ù…Ø§Ø¨Ø±Ø­\",\"Ù…Ø§Ø¯Ø§Ù…\",\"Ù…Ø§Ø°Ø§\",\"Ù…Ø§Ø²Ø§Ù„\",\"Ù…Ø§ÙØªØ¦\",\"Ù…Ø§ÙŠÙˆ\",\"Ù…ØªÙ‰\",\"Ù…Ø«Ù„\",\"Ù…Ø°\",\"Ù…Ø³Ø§Ø¡\",\"Ù…Ø¹\",\"Ù…Ø¹Ø§Ø°\",\"Ù…Ù‚Ø§Ø¨Ù„\",\"Ù…ÙƒØ§Ù†ÙƒÙ…\",\"Ù…ÙƒØ§Ù†ÙƒÙ…Ø§\",\"Ù…ÙƒØ§Ù†ÙƒÙ†Ù‘\",\"Ù…ÙƒØ§Ù†ÙÙƒ\",\"Ù…Ù„ÙŠØ§Ø±\",\"Ù…Ù„ÙŠÙˆÙ†\",\"Ù…Ù…Ø§\",\"Ù…Ù…Ù†\",\"Ù…Ù†\",\"Ù…Ù†Ø°\",\"Ù…Ù†Ù‡Ø§\",\"Ù…Ù‡\",\"Ù…Ù‡Ù…Ø§\",\"Ù…ÙÙ†Ù’\",\"Ù…ÙÙ†\",\"Ù†Ø­Ù†\",\"Ù†Ø­Ùˆ\",\"Ù†Ø¹Ù…\",\"Ù†ÙØ³\",\"Ù†ÙØ³Ù‡\",\"Ù†Ù‡Ø§ÙŠØ©\",\"Ù†ÙØ®Ù’\",\"Ù†ÙØ¹ÙÙ…Ù‘Ø§\",\"Ù†ÙØ¹Ù’Ù…Ù\",\"Ù‡Ø§\",\"Ù‡Ø§Ø¤Ù…\",\"Ù‡Ø§ÙƒÙ\",\"Ù‡Ø§Ù‡Ù†Ø§\",\"Ù‡Ø¨Ù‘\",\"Ù‡Ø°Ø§\",\"Ù‡Ø°Ù‡\",\"Ù‡ÙƒØ°Ø§\",\"Ù‡Ù„\",\"Ù‡Ù„Ù…Ù‘Ù\",\"Ù‡Ù„Ù‘Ø§\",\"Ù‡Ù…\",\"Ù‡Ù…Ø§\",\"Ù‡Ù†\",\"Ù‡Ù†Ø§\",\"Ù‡Ù†Ø§Ùƒ\",\"Ù‡Ù†Ø§Ù„Ùƒ\",\"Ù‡Ùˆ\",\"Ù‡ÙŠ\",\"Ù‡ÙŠØ§\",\"Ù‡ÙŠØª\",\"Ù‡ÙŠÙ‘Ø§\",\"Ù‡ÙØ¤Ù„Ø§Ø¡\",\"Ù‡ÙØ§ØªØ§Ù†Ù\",\"Ù‡ÙØ§ØªÙÙŠÙ’Ù†Ù\",\"Ù‡ÙØ§ØªÙÙ‡\",\"Ù‡ÙØ§ØªÙÙŠ\",\"Ù‡ÙØ¬Ù’\",\"Ù‡ÙØ°Ø§\",\"Ù‡ÙØ°Ø§Ù†Ù\",\"Ù‡ÙØ°ÙÙŠÙ’Ù†Ù\",\"Ù‡ÙØ°ÙÙ‡\",\"Ù‡ÙØ°ÙÙŠ\",\"Ù‡ÙÙŠÙ’Ù‡ÙØ§ØªÙ\",\"Ùˆ\",\"Ùˆ6\",\"ÙˆØ§\",\"ÙˆØ§Ø­Ø¯\",\"ÙˆØ§Ø¶Ø§Ù\",\"ÙˆØ§Ø¶Ø§ÙØª\",\"ÙˆØ§ÙƒØ¯\",\"ÙˆØ§Ù†\",\"ÙˆØ§Ù‡Ø§Ù‹\",\"ÙˆØ§ÙˆØ¶Ø­\",\"ÙˆØ±Ø§Ø¡ÙÙƒ\",\"ÙˆÙÙŠ\",\"ÙˆÙ‚Ø§Ù„\",\"ÙˆÙ‚Ø§Ù„Øª\",\"ÙˆÙ‚Ø¯\",\"ÙˆÙ‚Ù\",\"ÙˆÙƒØ§Ù†\",\"ÙˆÙƒØ§Ù†Øª\",\"ÙˆÙ„Ø§\",\"ÙˆÙ„Ù…\",\"ÙˆÙ…Ù†\",\"Ù…ÙÙ†\",\"ÙˆÙ‡Ùˆ\",\"ÙˆÙ‡ÙŠ\",\"ÙˆÙŠÙƒØ£Ù†Ù‘\",\"ÙˆÙÙŠÙ’\",\"ÙˆÙØ´Ù’ÙƒÙØ§Ù†ÙÙ\",\"ÙŠÙƒÙˆÙ†\",\"ÙŠÙ…ÙƒÙ†\",\"ÙŠÙˆÙ…\",\"Ù‘Ø£ÙŠÙ‘Ø§Ù†\"}\n",
        "\n",
        "# remove stop_words function \n",
        "def remove_stop_words(text):\n",
        "    zen = TextBlob(text)\n",
        "    words = zen.words\n",
        "    return \" \".join([w for w in words if not w in stops and not w in stop_word_comp and len(w) >= 2])\n",
        "\n",
        "# Data['clean_tweet'] = Data['clean_tweet'].apply(lambda x:remove_stop_words(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rf1fK1sS0xjM"
      },
      "outputs": [],
      "source": [
        "# apply normalization and remove diacritics (Tashkeel)\n",
        "\n",
        "def normalizeArabic(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(\"[Ø¥Ø£Ù±Ø¢Ø§]\", \"Ø§\", text)\n",
        "    text = re.sub(\"Ù‰\", \"ÙŠ\", text)\n",
        "    text = re.sub(\"Ø¤\", \"Ø¡\", text)\n",
        "    text = re.sub(\"Ø¦\", \"Ø¡\", text)\n",
        "    text = re.sub(\"Ø©\", \"Ù‡\", text)\n",
        "    noise = re.compile(\"\"\" Ù‘    | # Tashdid\n",
        "                             Ù    | # Fatha\n",
        "                             Ù‹    | # Tanwin Fath\n",
        "                             Ù    | # Damma\n",
        "                             ÙŒ    | # Tanwin Damm\n",
        "                             Ù    | # Kasra\n",
        "                             Ù    | # Tanwin Kasr\n",
        "                             Ù’    | # Sukun\n",
        "                             Ù€     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "    text = re.sub(noise, '', text)\n",
        "    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text) # Remove longation\n",
        "    return araby.strip_tashkeel(text)\n",
        "\n",
        "# Data['clean_tweet'] = Data['clean_tweet'].apply(lambda x:normalizeArabic(x))\n",
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sbsqQClfvPKc",
        "outputId": "bd6a1273-b710-415d-b9da-83a5e538f5b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   tweet_id  \\\n",
              "0       1175358310087892992   \n",
              "1       1175416117793349632   \n",
              "2       1175450108898565888   \n",
              "3       1175471073770573824   \n",
              "4       1175496913145217024   \n",
              "...                     ...   \n",
              "458192  1019484980282580992   \n",
              "458193  1021083283709407232   \n",
              "458194  1017477537889431552   \n",
              "458195  1022430374696239232   \n",
              "458196  1022409931029458944   \n",
              "\n",
              "                                                    tweet dialect  \\\n",
              "0        @Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .      IQ   \n",
              "1       @7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...      IQ   \n",
              "2                         @KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ      IQ   \n",
              "3              @HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’      IQ   \n",
              "4                      @hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº      IQ   \n",
              "...                                                   ...     ...   \n",
              "458192              @Al_mhbaa_7 Ù…Ø¨Ø³ÙˆØ·ÙŠÙ† Ù…Ù†Ùƒ Ø§Ù„Ù„ÙŠ Ø¨Ø§Ø³Ø·Ø§Ù†Ø§ğŸ˜…      BH   \n",
              "458193       @Zzainabali @P_ameerah ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ÙŠÙ†Ø¯Ù‡ Ø§Ø¨Ø´ ÙŠØ®ØªÙŠ      BH   \n",
              "458194  @Al_mhbaa_7 Ø´Ùˆ Ø¹Ù…Ù„Ù†Ø§ Ù„Ùƒ Ø­Ù†Ø§ ØªÙ‡Ø±Ø¨ÙŠ Ù…Ù†Ù†Ø§ Ø§Ø­Ù†Ø§ Ù…Ø³...      BH   \n",
              "458195        @haneenalmwla Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙÙŠÙ‡Ø§ ÙˆØ¨Ø§Ù„Ø¹Ø§ÙÙŠÙ‡ ğŸ˜‹ğŸ˜‹ğŸ˜‹      BH   \n",
              "458196          @jolnar121 Ø§Ù„Ø³Ø­Ù„Ù‡ Ø¶ÙŠÙÙŠ ÙŠ Ø¨ØªØ·Ù„Ø¹ Ù„Ùƒ Ø³Ø­Ù„ÙŠÙ‡ğŸ˜…ğŸ˜…      BH   \n",
              "\n",
              "                                              clean_tweet  \n",
              "0                                     Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠÙ‡ ÙŠÙ†ØªÙØ¶ ÙŠØºÙŠØ±  \n",
              "1       ÙŠØ¹Ù†ÙŠ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„ÙŠ Ø§Ù„Ø¨Ø´Ø± Ø­ÙŠÙˆÙ†Ù‡ ÙˆÙˆØ­Ø´ÙŠÙ‡ ÙˆØªØ·Ù„Ø¨ÙˆÙ† Ø§Ù„ØºØ±...  \n",
              "2                                        Ù…Ø¨ÙŠÙ† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ  \n",
              "3                               ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡  \n",
              "4                                      ÙˆÙŠÙ† Ø§Ù„ØºÙŠØ¨Ù‡ Ø§Ø® Ù…Ø­Ù…Ø¯  \n",
              "...                                                   ...  \n",
              "458192                           Ù…Ø¨Ø³ÙˆØ·ÙŠÙ† Ù…Ù†Ùƒ Ø§Ù„Ù„ÙŠ Ø¨Ø§Ø³Ø·Ø§Ù†Ø§  \n",
              "458193                              ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ÙŠÙ†Ø¯Ù‡ Ø§Ø¨Ø´ ÙŠØ®ØªÙŠ  \n",
              "458194  Ø´Ùˆ Ø¹Ù…Ù„Ù†Ø§ Ø­Ù†Ø§ ØªÙ‡Ø±Ø¨ÙŠ Ù…Ù†Ù†Ø§ Ø§Ø­Ù†Ø§ Ù…Ø³Ø§ÙƒÙŠÙ† Ù„ÙŠØ´ Ø¨ØªØ¹Ù…Ù„ÙŠ...  \n",
              "458195                               Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙˆØ¨Ø§Ù„Ø¹Ø§ÙÙŠÙ‡  \n",
              "458196                            Ø§Ù„Ø³Ø­Ù„Ù‡ Ø¶ÙŠÙÙŠ Ø¨ØªØ·Ù„Ø¹ Ø³Ø­Ù„ÙŠÙ‡  \n",
              "\n",
              "[458197 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c6f4cb9-f657-44f6-be09-464629a58732\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>dialect</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1175358310087892992</td>\n",
              "      <td>@Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .</td>\n",
              "      <td>IQ</td>\n",
              "      <td>Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠÙ‡ ÙŠÙ†ØªÙØ¶ ÙŠØºÙŠØ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1175416117793349632</td>\n",
              "      <td>@7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...</td>\n",
              "      <td>IQ</td>\n",
              "      <td>ÙŠØ¹Ù†ÙŠ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„ÙŠ Ø§Ù„Ø¨Ø´Ø± Ø­ÙŠÙˆÙ†Ù‡ ÙˆÙˆØ­Ø´ÙŠÙ‡ ÙˆØªØ·Ù„Ø¨ÙˆÙ† Ø§Ù„ØºØ±...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1175450108898565888</td>\n",
              "      <td>@KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ</td>\n",
              "      <td>IQ</td>\n",
              "      <td>Ù…Ø¨ÙŠÙ† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1175471073770573824</td>\n",
              "      <td>@HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’</td>\n",
              "      <td>IQ</td>\n",
              "      <td>ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1175496913145217024</td>\n",
              "      <td>@hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº</td>\n",
              "      <td>IQ</td>\n",
              "      <td>ÙˆÙŠÙ† Ø§Ù„ØºÙŠØ¨Ù‡ Ø§Ø® Ù…Ø­Ù…Ø¯</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458192</th>\n",
              "      <td>1019484980282580992</td>\n",
              "      <td>@Al_mhbaa_7 Ù…Ø¨Ø³ÙˆØ·ÙŠÙ† Ù…Ù†Ùƒ Ø§Ù„Ù„ÙŠ Ø¨Ø§Ø³Ø·Ø§Ù†Ø§ğŸ˜…</td>\n",
              "      <td>BH</td>\n",
              "      <td>Ù…Ø¨Ø³ÙˆØ·ÙŠÙ† Ù…Ù†Ùƒ Ø§Ù„Ù„ÙŠ Ø¨Ø§Ø³Ø·Ø§Ù†Ø§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458193</th>\n",
              "      <td>1021083283709407232</td>\n",
              "      <td>@Zzainabali @P_ameerah ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ÙŠÙ†Ø¯Ù‡ Ø§Ø¨Ø´ ÙŠØ®ØªÙŠ</td>\n",
              "      <td>BH</td>\n",
              "      <td>ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ÙŠÙ†Ø¯Ù‡ Ø§Ø¨Ø´ ÙŠØ®ØªÙŠ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458194</th>\n",
              "      <td>1017477537889431552</td>\n",
              "      <td>@Al_mhbaa_7 Ø´Ùˆ Ø¹Ù…Ù„Ù†Ø§ Ù„Ùƒ Ø­Ù†Ø§ ØªÙ‡Ø±Ø¨ÙŠ Ù…Ù†Ù†Ø§ Ø§Ø­Ù†Ø§ Ù…Ø³...</td>\n",
              "      <td>BH</td>\n",
              "      <td>Ø´Ùˆ Ø¹Ù…Ù„Ù†Ø§ Ø­Ù†Ø§ ØªÙ‡Ø±Ø¨ÙŠ Ù…Ù†Ù†Ø§ Ø§Ø­Ù†Ø§ Ù…Ø³Ø§ÙƒÙŠÙ† Ù„ÙŠØ´ Ø¨ØªØ¹Ù…Ù„ÙŠ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458195</th>\n",
              "      <td>1022430374696239232</td>\n",
              "      <td>@haneenalmwla Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙÙŠÙ‡Ø§ ÙˆØ¨Ø§Ù„Ø¹Ø§ÙÙŠÙ‡ ğŸ˜‹ğŸ˜‹ğŸ˜‹</td>\n",
              "      <td>BH</td>\n",
              "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙˆØ¨Ø§Ù„Ø¹Ø§ÙÙŠÙ‡</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458196</th>\n",
              "      <td>1022409931029458944</td>\n",
              "      <td>@jolnar121 Ø§Ù„Ø³Ø­Ù„Ù‡ Ø¶ÙŠÙÙŠ ÙŠ Ø¨ØªØ·Ù„Ø¹ Ù„Ùƒ Ø³Ø­Ù„ÙŠÙ‡ğŸ˜…ğŸ˜…</td>\n",
              "      <td>BH</td>\n",
              "      <td>Ø§Ù„Ø³Ø­Ù„Ù‡ Ø¶ÙŠÙÙŠ Ø¨ØªØ·Ù„Ø¹ Ø³Ø­Ù„ÙŠÙ‡</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>458197 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c6f4cb9-f657-44f6-be09-464629a58732')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c6f4cb9-f657-44f6-be09-464629a58732 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c6f4cb9-f657-44f6-be09-464629a58732');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "## Clean for tweets\n",
        "  text = clean_tweet(text)\n",
        "## Remove Emojis\n",
        "  text = remove_emoji(text)\n",
        "## Remove Tashkeel\n",
        "  text = normalizeArabic(text) \n",
        "## Remove punctuations\n",
        "  text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,ØŒ-./:;<=>ØŸ?@[\\]^_`{|}~\"\"\"), ' ', text)  # remove punctuation\n",
        "## Remove stop words\n",
        "  text = remove_stop_words(text)\n",
        "## remove extra whitespace\n",
        "  text = re.sub('\\s+', ' ', text)  \n",
        "# ## Remove numbers\n",
        "  text = re.sub(\"\\d+\", \" \", text)\n",
        "  text = re.sub('\\W+', ' ', text) \n",
        "  text = re.sub('[A-Za-z]+',' ',text)\n",
        "  text = re.sub(r'\\\\u[A-Za-z0-9\\\\]+',' ',text)\n",
        "#   ## remove extra whitespace\n",
        "  text = re.sub('\\s+', ' ', text)  \n",
        "\n",
        "  return text\n",
        "\n",
        "Data['clean_tweet'] = Data['tweet'].apply(lambda x:clean_text(x))\n",
        "Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G4k4fKWWfhE4"
      },
      "outputs": [],
      "source": [
        "# split clean words \n",
        "def  tokenize_text(df, text_field, new_text_field_name):\n",
        "     df[new_text_field_name] = df[text_field].apply(lambda x:' +'.join(  araby.tokenize(x)))\n",
        "    \n",
        "     return df\n",
        "dftoken= tokenize_text(Data,\"clean_tweet\",\"clean_tweet_split\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wlWhugCR9pcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f589c3-4a76-45a6-92ad-0f8777bc21f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done remove the following most Common words :  ['+Ø§Ù„Ù„ÙŠ', '+Ø¹Ù„ÙŠ', '+Ø§Ù„Ù„Ù‡', '+Ù…Ø´', '+Ø§Ù†Ø§', '+Ø´ÙŠ', '+ÙˆØ§Ù„Ù„Ù‡', '+Ø§Ù†Øª', '+Ø§Ù„ÙŠ', '+Ø¹Ø´Ø§Ù†', '+Ø§Ù„Ù†Ø§Ø³', 'Ø§Ù†Ø§']\n"
          ]
        }
      ],
      "source": [
        "# ### Common word removal\n",
        "freq = pd.Series(' '.join(Data['clean_tweet_split']).split()).value_counts()[:12]\n",
        "freq = list(freq.index)\n",
        "Data['clean_tweet_split'] = Data['clean_tweet_split'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
        "print(\"Done remove the following most Common words : \",freq )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_QTyHPddmZMX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}